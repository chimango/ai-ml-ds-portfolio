{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    r\"C:\\Users\\pandas\\Documents\\Sam\\Dataset\"\n",
    ").load_data()\n",
    "# index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4ed4f4624b4042b7b66fb671fedcdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/481 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d890209e226b4fdc99609976ec4dc172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# documents\n",
    "index = VectorStoreIndex.from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What are factors that can affect the reliability of interpretation of laboratory test results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Factors that can affect the reliability of interpretation of laboratory test results include inappropriate specimen collection, delay in transportation or processing leading to contamination, use of incorrect transport or storage containers, administration of antibiotics before specimen collection, and improper storage temperature.', source_nodes=[NodeWithScore(node=TextNode(id_='12f6c4ed-2495-43bf-a0a8-cf0c8ac01356', embedding=None, metadata={'page_label': '29', 'file_name': 'WHO-AF-WHE-CPI-01-2019-eng.pdf', 'file_path': 'C:\\\\Users\\\\pandas\\\\Documents\\\\Sam\\\\Dataset\\\\WHO-AF-WHE-CPI-01-2019-eng.pdf', 'file_type': 'application/pdf', 'file_size': 2363070, 'creation_date': '2024-08-17', 'last_modified_date': '2024-07-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ed9063a8-56be-47be-8ec8-9e8383c520c3', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '29', 'file_name': 'WHO-AF-WHE-CPI-01-2019-eng.pdf', 'file_path': 'C:\\\\Users\\\\pandas\\\\Documents\\\\Sam\\\\Dataset\\\\WHO-AF-WHE-CPI-01-2019-eng.pdf', 'file_type': 'application/pdf', 'file_size': 2363070, 'creation_date': '2024-08-17', 'last_modified_date': '2024-07-09'}, hash='3c934205d1d9e9a84072437d5dc86caecb886ccf6f9ab20ce611b3738cf5b6e6')}, text='11Many factors can affect the reliability of interpretation of laboratory test results. For example, \\nresults are difficult to interpret when:\\n(a) A specimen is collected inappropriately, for example, a blood specimen has haemolysed.\\n(b) Delay in transportation and/or processing may result in bacterial contamination in a \\ncollected specimen such as urine.\\n(c) Use of wrong transport or storage media or container may cause reduced viability of the \\nsuspected organism.\\n(d) Given antibiotics before specimen for cultures are collected.\\n(e) Wrong temperature is used for storage of specimen.\\nThe disease-specific reference tables in section 11 list recommended laboratory procedures \\nfor confirming priority diseases and conditions including:\\n(a) The diagnostic test for confirming the disease or condition\\n(b) The specimen to be collected\\n(c) When to collect the specimen\\n(d) How to collect the specimen\\n(e) How to prepare, store and transport the specimen\\n(f) When to expect the results\\n(g) Sources for additional information.\\nIt is necessary to initiate public health measures even before laboratory confirmation has \\nbeen received. It should be noted that the patient should be contained basing on signs and \\nsymptoms, and case management should be initiated immediately even prior to laboratory \\nresults such as in the case of Viral Haemorrhagic Fevers.\\n1.6.2 Establish a laboratory network\\nThe local surveillance and the laboratory focal persons at each level of the health system should \\nmaintain an updated list of the laboratories that have the capacity to perform required \\nlaboratory testing. A sample worksheet for listing national laboratories for confirming priority \\ndiseases and conditions is in Annex 1F of this section. Provide information to all health facilities \\nabout the methods for transporting specimens including how to prepare, handle, ship and store \\nthe specimens. Make sure to disseminate information about packing and shipping infectious \\nmaterial as directed by national policy.', mimetype='text/plain', start_char_idx=0, end_char_idx=2010, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8573343928760387), NodeWithScore(node=TextNode(id_='f73fe5f1-3cc4-4bb5-b3dc-731ef33adfd0', embedding=None, metadata={'page_label': '65', 'file_name': 'WHO-AF-WHE-CPI-01-2019-eng.pdf', 'file_path': 'C:\\\\Users\\\\pandas\\\\Documents\\\\Sam\\\\Dataset\\\\WHO-AF-WHE-CPI-01-2019-eng.pdf', 'file_type': 'application/pdf', 'file_size': 2363070, 'creation_date': '2024-08-17', 'last_modified_date': '2024-07-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='268b86aa-4d85-4a9e-b1ff-bbe0c728e0a2', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '65', 'file_name': 'WHO-AF-WHE-CPI-01-2019-eng.pdf', 'file_path': 'C:\\\\Users\\\\pandas\\\\Documents\\\\Sam\\\\Dataset\\\\WHO-AF-WHE-CPI-01-2019-eng.pdf', 'file_type': 'application/pdf', 'file_size': 2363070, 'creation_date': '2024-08-17', 'last_modified_date': '2024-07-09'}, hash='e1067347e11f3e5cd965e6e54efced9f335672dcc49210cdde5583981cd0cda8')}, text='47(g) Receive results from the laboratory and promptly report them according to country \\nprocedures to all that require them for public health action and patient clinical care. \\n(h) Ensure that there is a proper record for laboratory results.\\n(i) Communicate with reference laboratory and National Laboratory Coordinators as \\nnecessary.\\n(j) Ensure that the laboratories have a quality assurance programme to improve the reliability \\nand reproducibility of laboratory results.\\nDistrict laboratory focal person \\n(a) Establish or strengthen routine communication with identified laboratories that receive \\nspecimens and health facilities or districts sending the specimens.\\n(b) Maintain and update list of inventory of supplies, reagents and equipment from all the \\nhealth facilities and laboratories in the district.\\n(c) Ensure that procedures for sample collection, transportation, confirming the disease or \\ncondition and reporting the results are clear and can be reliably carried out in the \\ndesignated places.\\n(d) Communicate with Regional laboratory focal person.\\n(e) Communicate with the national reference laboratory as required.\\n(f) Ensure that there is a proper record for laboratory results.\\n(g) Ensure that the laboratories have a quality assurance programme to improve the reliability \\nand reproducibility of laboratory results.\\nFacility laboratory focal person \\n(a) Maintain and update list of inventory of supplies, reagents and equipment at the facility.\\n(b) Ensure that standard operating procedures (SOP) for sample collection, transportation, \\nconfirming the disease or condition and reporting the results are available and being \\nfollowed.\\n(c) Communicate with district laboratory focal person and regional laboratory focal person as \\nrequired.\\n(d) Ensure that there is a proper record for laboratory results.\\n(e) Ensure that the laboratory has a quality assurance programme (internal and external quality \\ncontrol) to improve the reliability and reproducibility of laboratory results.', mimetype='text/plain', start_char_idx=0, end_char_idx=2003, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8079952221872116)], metadata={'12f6c4ed-2495-43bf-a0a8-cf0c8ac01356': {'page_label': '29', 'file_name': 'WHO-AF-WHE-CPI-01-2019-eng.pdf', 'file_path': 'C:\\\\Users\\\\pandas\\\\Documents\\\\Sam\\\\Dataset\\\\WHO-AF-WHE-CPI-01-2019-eng.pdf', 'file_type': 'application/pdf', 'file_size': 2363070, 'creation_date': '2024-08-17', 'last_modified_date': '2024-07-09'}, 'f73fe5f1-3cc4-4bb5-b3dc-731ef33adfd0': {'page_label': '65', 'file_name': 'WHO-AF-WHE-CPI-01-2019-eng.pdf', 'file_path': 'C:\\\\Users\\\\pandas\\\\Documents\\\\Sam\\\\Dataset\\\\WHO-AF-WHE-CPI-01-2019-eng.pdf', 'file_type': 'application/pdf', 'file_size': 2363070, 'creation_date': '2024-08-17', 'last_modified_date': '2024-07-09'}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.pprint_utils import pprint_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pprint_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pprint_response(response,show_source\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pprint_response' is not defined"
     ]
    }
   ],
   "source": [
    "pprint_response(response,show_source=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSIST_DIR = \"./storage\"\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    documents = SimpleDirectoryReader(\n",
    "        r\"C:\\Users\\pandas\\Documents\\Sam\\Dataset\"\n",
    "        ).load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents=documents)\n",
    "    index.storage_context.persist(PERSIST_DIR)\n",
    "\n",
    "else:\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.27105955957686534 seconds as it raised APIConnectionError: Connection error..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Integrated Disease Surveillance and Response strategy is an approach adopted by WHO/AFRO Member States in September 1998 to improve public health surveillance and response for priority diseases, conditions, and events at various levels such as community, health facility, district, and national levels. This strategy promotes the rational and efficient use of resources by integrating and streamlining common surveillance activities and functions, making surveillance and laboratory data more usable. It helps public health managers and decision-makers improve the detection and response to the leading causes of illness, death, and disability in African countries.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What  Integrated Disease Surveillance and Response strategy?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcamelot\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pandas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\camelot\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__version__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_pdf\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PlotMethods\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# set up logging\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pandas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\camelot\\io.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFHandler\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_input, remove_extra\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_pdf\u001b[39m(\n\u001b[0;32m     10\u001b[0m     filepath,\n\u001b[0;32m     11\u001b[0m     pages\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     17\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\pandas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\camelot\\handlers.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPyPDF2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfFileReader, PdfFileWriter\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TableList\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Stream, Lattice\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     TemporaryDirectory,\n\u001b[0;32m     12\u001b[0m     get_page_layout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     download_url,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPDFHandler\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\pandas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\camelot\\parsers\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstream\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Stream\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlattice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lattice\n",
      "File \u001b[1;32mc:\\Users\\pandas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\camelot\\parsers\\lattice.py:26\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Table\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     scale_image,\n\u001b[0;32m     18\u001b[0m     scale_pdf,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     compute_whitespace,\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     adaptive_threshold,\n\u001b[0;32m     28\u001b[0m     find_lines,\n\u001b[0;32m     29\u001b[0m     find_contours,\n\u001b[0;32m     30\u001b[0m     find_joints,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     34\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamelot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLattice\u001b[39;00m(BaseParser):\n",
      "File \u001b[1;32mc:\\Users\\pandas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\camelot\\image_processing.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madaptive_threshold\u001b[39m(imagename, process_background\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import camelot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\pandas\\Documents\\mmh.pdf\"\n",
    "texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "        data_path\n",
    "        ).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m documents\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'text'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:\\Users\\pandas\\Documents\\clinics\\mmh_facilities.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract text from the PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "# Function to parse the extracted text into structured data\n",
    "def parse_health_facility_data(text):\n",
    "    lines = text.splitlines()\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        # Match the pattern of the health facility data\n",
    "        match = re.match(r\"(.+?)\\s+(.+?)\\s+(.+?)\\s+(.+?)\\s+(Health Centre|Hospital)\\s+(Government|CHAM)\\s+(Urban|Rural)\", line)\n",
    "        if match:\n",
    "            region, zone, district, facility_name, facility_type, managing_authority, location = match.groups()\n",
    "            data.append({\n",
    "                \"Region\": region,\n",
    "                \"Zone\": zone,\n",
    "                \"District\": district,\n",
    "                \"Facility Name\": facility_name,\n",
    "                \"Facility Type\": facility_type,\n",
    "                \"Managing Authority\": managing_authority,\n",
    "                \"Urban/Rural\": location\n",
    "            })\n",
    "    return data\n",
    "\n",
    "# Main function to run the script\n",
    "def main():\n",
    "    pdf_path = r\"C:\\Users\\pandas\\Documents\\clinics\\mmh.pdf\"  # Replace with your PDF path\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    facilities = parse_health_facility_data(text)\n",
    "    \n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    df = pd.DataFrame(facilities)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_path = r\"C:\\Users\\pandas\\Documents\\clinics\\mmh_facilities.csv\"  # Replace with your desired CSV path\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"C:\\Users\\pandas\\Documents\\clinics\\mmh_facilities.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "district = []\n",
    "for fas in df[\"Facility Name\"]:\n",
    "    district.append(fas.split()[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['District_2']=district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facility  = []\n",
    "# for fas in df[\"Facility Name\"]:\n",
    "#     # district.append(fas.split()[0])\n",
    "#     print(f\"{fas}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_first_word(sentences):\n",
    "    remaining_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Split the sentence into words, then join the rest after the first word\n",
    "        remaining_sentence = ' '.join(sentence.split()[1:])\n",
    "        remaining_sentences.append(remaining_sentence)\n",
    "    return remaining_sentences\n",
    "\n",
    "# Get the remaining part of each sentence after removing the first word\n",
    "remaining_facilities = remove_first_word(df[\"Facility Name\"])\n",
    "\n",
    "# # Print the results\n",
    "# for facility in remaining_facilities:\n",
    "#     print(facility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"facilities\"] = remaining_facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\pandas\\Documents\\clinics\\facilities.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "# Pinecone setup (initialize and connect to the index)\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# Define the Pinecone index\n",
    "index_name = \"idsr\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # Use the dimension that matches the embedding model\n",
    "        metric='cosine',  # Or use 'euclidean' or 'dotproduct', depending on your use case\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region=os.getenv(\"PINECONE_REGION\", \"us-east-1\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model\n",
    "embedding_model = OpenAIEmbedding(model_name=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "RAW_DATA = \"./data/raw\"\n",
    "PERSIST_DIR = \"./data/storage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(RAW_DATA).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 \\n \\nHumanitarian emergencies have major implications for the populations where they occur and \\nfor their health services surveillance systems (WHO, 2012). Emergencies typically result in \\npopulation displacement to congested settings where access to basic needs like water, food, \\nshelter and other social services are constrained. These conditions increase the risk of death \\nfrom common epidemic and endemic diseases.  \\n \\nConsequently, effective public health surveillance and outbreak response is a priority during \\npublic health emergencies in affected populations. Due to the disruption of health and other \\nsocial services during the emergencies, the routine IDSR system must be enhanced to meet \\nthe public health surveillance and outbreak response needs in humanitarian contexts. In \\nthese settings, IDSR should be tailored to the prevailing context to meet the additional \\nemergency needs. \\n \\nSimilarly, an Enhanced IDSR system should be established in such settings to address the \\nhumanitarian emergency. It should be based on the IDSR strategy, structures, tools, \\nguidelines and resources, but should ensure the flexibility required in addressing the \\nsurveillance and response needs of affected populations in emergency situations. This should \\nbe done within the existing national IDSR system.  \\n \\nThis section introduces key principles of implementing IDSR in complex humanitarian \\nemergencies. This will involve enhancing IDSR core functions to ensure early detection, \\nassessment and response to acute public health events. For a more detailed description, \\nplease refer to the WHO document on early detection, assessment and response to acute \\npublic health events - implementation of early warning and response with focus on event-\\nbased surveillance, (WHO, 2014). \\n \\n \\nAcute and protracted crises have major immediate and long-term effects on population \\nhealth and health systems. Conflicts and disasters create disruptions in the overall \\nfunctionality of the health system.  In such situations, the routine IDSR system may be \\nunderperforming or may be disrupted. The IDSR must therefore be tailored to adequately \\nmeet the surveillance information needs of a humanitarian emergency. Examples of such \\nhumanitarian emergencies include: armed conflict, famine, natural disasters and other \\nmajor emergencies. \\n \\n  '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for doc in documents:\n",
    "#     print(doc.metadata[\"file_name\"])\n",
    "\n",
    "# documents[0].metadata[\"file_name\"]\n",
    "documents[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from PyPDF2 import PdfReader\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and process PDF, removing newlines, trailing spaces, and symbols\n",
    "def load_and_process_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        extracted_text = page.extract_text()\n",
    "        # Replace newlines with spaces and remove trailing spaces\n",
    "        cleaned_text = extracted_text.replace('\\n', ' ').strip()\n",
    "        text += cleaned_text + \" \"  # Add space to separate different lines or pages\n",
    "    \n",
    "    return text.strip()  # Remove any trailing spaces after processing all pages\n",
    "\n",
    "# Prepare documents and embeddings\n",
    "def prepare_documents(pdf_directory):\n",
    "    documents = []\n",
    "    for file_name in os.listdir(pdf_directory):\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(pdf_directory, file_name)\n",
    "            text = load_and_process_pdf(file_path)\n",
    "            document = Document(\n",
    "                text=text,\n",
    "                metadata={'doc_id': file_name.split(\".pdf\")[0]}  # Storing document name as metadata\n",
    "            )\n",
    "            documents.append(document)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = prepare_documents(RAW_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c13067ad-3044-4a8a-81e7-2b8caca16572'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into chunks with overlap\n",
    "def split_text_into_chunks(text, chunk_size=1000, overlap=200):\n",
    "    words = text.replace('\\n', ' ').split()\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = start + chunk_size\n",
    "        yield \" \".join(words[start:end])\n",
    "        start += chunk_size - overlap  # Move start forward but include overlap\n",
    "\n",
    "# Load or create index\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    documents = SimpleDirectoryReader(RAW_DATA).load_data()\n",
    "    \n",
    "    # For each document, split into chunks, get embedding, and insert into Pinecone\n",
    "    for doc in documents:\n",
    "        # Split document text into smaller chunks with overlap\n",
    "        for chunk_id, chunk_text in enumerate(split_text_into_chunks(doc.text)):\n",
    "            # Convert chunk to embedding\n",
    "            embedding = embedding_model.get_text_embedding(chunk_text)\n",
    "            \n",
    "            # Upsert to Pinecone, storing chunk metadata\n",
    "            index.upsert(\n",
    "                vectors=[{\n",
    "                    \"id\": f\"{doc.id_}_{chunk_id}\",  # Create a unique ID for each chunk\n",
    "                    \"values\": embedding,\n",
    "                    \"metadata\": {\n",
    "                        \"document_name\": doc.metadata[\"file_name\"].split(\".pdf\")[0],  # Original document metadata\n",
    "                        \"chunk_id\": chunk_id  # Track chunk number\n",
    "                    }\n",
    "                }],\n",
    "                namespace=\"pandas\"  # Replace with a namespace of your choice\n",
    "            )\n",
    "    \n",
    "    # Persist local storage context (for metadata or other needs)\n",
    "    VectorStoreIndex.from_documents(documents).storage_context.persist(PERSIST_DIR)\n",
    "else:\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context=storage_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = OpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    ")\n",
    "\n",
    "embeddings = embed_model.get_text_embedding(\n",
    "    \"Open AI new Embeddings models is awesome.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query engine setup (as_query_engine will still be used for metadata querying)\n",
    "query_engine = VectorStoreIndex.as_query_engine()\n",
    "\n",
    "# Query with metadata filter and a threshold using Pinecone\n",
    "def query_with_filter(query, document_filter=None, threshold=0.7, top_k=5):\n",
    "    # Convert query text to embedding\n",
    "    query_embedding = embedding_model.get_embedding(query)\n",
    "    \n",
    "    # Filter for specific documents based on metadata (e.g., document name)\n",
    "    if document_filter:\n",
    "        pinecone_filter = {\"document_name\": {\"$eq\": document_filter}}\n",
    "    else:\n",
    "        pinecone_filter = None\n",
    "\n",
    "    # Query Pinecone with the embedding, applying the metadata filter\n",
    "    result = index.query(\n",
    "        namespace=\"pandas\",  # Use the same namespace as above\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_values=True,\n",
    "        include_metadata=True,\n",
    "        filter=pinecone_filter\n",
    "    )\n",
    "\n",
    "    # Apply the similarity threshold\n",
    "    relevant_results = [item for item in result['matches'] if item['score'] >= threshold]\n",
    "\n",
    "    return relevant_results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "query = \"how to report priority diseases\"\n",
    "filtered_results = query_with_filter(query, document_filter=\"section 1\", threshold=0.7, top_k=5)\n",
    "\n",
    "# Display results\n",
    "for result in filtered_results:\n",
    "    print(f\"Document: {result['metadata']['document_name']}\")\n",
    "    print(f\"Score: {result['score']}\")\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pinecone\n",
    "from pinecone import Pinecone\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "# Pinecone setup (initialize and connect to the index)\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "index_name = \"idsr\"  # The same index name used during the embedding\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model\n",
    "embedding_model = OpenAIEmbedding(model_name=\"text-embedding-ada-002\")\n",
    "\n",
    "# Query function\n",
    "def query_pinecone(query_text, top_k=5, namespace=\"pandas\", threshold=0.7, document_filter=None):\n",
    "    # Convert the query text to an embedding\n",
    "    query_embedding = embedding_model.get_text_embedding(query_text)\n",
    "\n",
    "    # Set up the filter (optional)\n",
    "    pinecone_filter = None\n",
    "    if document_filter:\n",
    "        pinecone_filter = {\"doc_uuid\": {\"$eq\": document_filter}}\n",
    "\n",
    "    # Query Pinecone with the embedding\n",
    "    query_result = index.query(\n",
    "        namespace=namespace,  # Use the same namespace as used in the embedding script\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        include_values=True,\n",
    "        filter=pinecone_filter\n",
    "    )\n",
    "\n",
    "    # Filter results by the score threshold (optional)\n",
    "    relevant_results = [item for item in query_result['matches'] if item['score'] >= threshold]\n",
    "\n",
    "    return relevant_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "query_text = \"Compare the laboratory confirmation methods for Chikungunya and diabetes, and which diseases are diagnosed through blood glucose measurements?\"  # Your query here\n",
    "document_filter = \"c2ac4183-a5ae-496a-98f0-48413c625caf\"\n",
    "top_k_results = query_pinecone(query_text, top_k=5, document_filter=document_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_k_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document UUID: c2ac4183-a5ae-496a-98f0-48413c625caf\n",
      "Chunk ID: 0.0\n",
      "Chunk ID: 27Priority Diseases and Conditions Disease/Condition Standard case definition for suspectedcases Confirmed case: A probable case AND One of the following (a)Detection of YF-specific* IgM (b)Detection of four-fold increase in YF IgM and/or IgG antibody titres between acute and convalescent serum samples (c)Detection of YFV- specific* neutralizing antibodies *YF-specific means that antibody tests (such as IgM or neutralizing antibody) for otherprevalent flavivirus are negative. This testing should include at least IgM for Dengue and West Nile and may include other flavivirus depending on local epidemiology. OR One of the following: (a)Detection of YF virus genome in blood or other organs by PCR (b)Detection of yellow fever antigen in blood, liver or other organs by immunoassays Isolation of the yellow fever virus Zika virus diseaseSuspected Case: A person presenting rash and/or fever and at least one of the following signs or symptoms: (a) arthralgia; or (b) arthritis; or (c) conjunctivitis (non-purulent/hyperaemic). Probable case: A suspected case with presence of IgM antibody against Zika virus and an epidemiological link (with no evidence of infection with other flaviviruses). Confirmed case: A person with laboratory confirmation of recent Zika virus infection: presence of Zika virus RNA or antigen in serum or other samples (for example, saliva, urine, tissue, whole blood); or IgM antibody against Zika virus positive (commercially available ELISA) These case definitions may change based on new knowledge\n",
      "Score: 0.831019342\n",
      "\n",
      "\n",
      "Document UUID: c2ac4183-a5ae-496a-98f0-48413c625caf\n",
      "Chunk ID: 0.0\n",
      "Chunk ID: 11Many factors can affect the reliability of interpretation of laboratory test results. For example, results are difficult to interpret when: (a) A specimen is collected inappropriately, for example, a blood specimen has haemolysed. (b) Delay in transportation and/or processing may result in bacterial contamination in a collected specimen such as urine. (c) Use of wrong transport or storage media or container may cause reduced viability of the suspected organism. (d) Given antibiotics before specimen for cultures are collected. (e) Wrong temperature is used for storage of specimen. The disease-specific reference tables in section 11 list recommended laboratory procedures for confirming priority diseases and conditions including: (a) The diagnostic test for confirming the disease or condition (b) The specimen to be collected (c) When to collect the specimen (d) How to collect the specimen (e) How to prepare, store and transport the specimen (f) When to expect the results (g) Sources for additional information. It is necessary to initiate public health measures even before laboratory confirmation has been received. It should be noted that the patient should be contained basing on signs and symptoms, and case management should be initiated immediately even prior to laboratory results such as in the case of Viral Haemorrhagic Fevers. 1.6.2 Establish a laboratory network The local surveillance and the laboratory focal persons at each level of the health system should maintain an updated list of the laboratories that have the capacity to perform required laboratory testing. A sample worksheet for listing national laboratories for confirming priority diseases and conditions is in Annex 1F of this section. Provide information to all health facilities about the methods for transporting specimens including how to prepare, handle, ship and store the specimens. Make sure to disseminate information about packing and shipping infectious material as directed by national policy.\n",
      "Score: 0.820325434\n",
      "\n",
      "\n",
      "Document UUID: c2ac4183-a5ae-496a-98f0-48413c625caf\n",
      "Chunk ID: 0.0\n",
      "Chunk ID: 20Priority Diseases and Conditions Disease/Condition Standard case definition for suspectedcases Lassa and Crimean- Congo Haemorrhagic Fevers (CCHF)Suspected case of CCHF : Illness with sudden onset of fever, malaise, weakness, irritability, headache, severe pain in limbs and loins and marked anorexia. Early development of flush on face and chest and conjunctival infection, haemorrhagic exanthema of soft palate, uvula and pharynx, and often fine petechial rash spreading from the chest and abdomen to the rest of the body, sometimes with largepurpuric areas. Confirmed case of CCHF : A suspected case with laboratory confirmation (positive IgM antibody, PCR, viral isolation or IgG seroconversion by ELISA or IFA) or epidemiological link to confirmed cases or outbreak. Suspected case of Lassa Fever : Illness with gradual onset with one or more of the following: malaise, fever, headache, sore throat, cough, nausea, vomiting, diarrhoea, myalgia, chest pain hearing loss and a history of contact with excreta of rodents or with a caseof Lassa Fever Confirmed case of Lassa Fever: A suspected case that is laboratory confirmed (positive IgM antibody, PCR or virus isolation) or epidemiologically linked to a laboratory confirmed case. LeprosySuspected case : A person showing one of three cardinal signs of leprosy: hypo-pigmented or reddish skin lesion, loss or decrease of sensations in skin patch, enlargement or peripheral nerve. Confirmed case: A person showing at least two cardinal signs of leprosy and who has not completed a full course of treatment with Multi Drug Therapy (MDT). Lymphatic FilariasisSuspected case : Resident of an endemic area with a clinical sign of hydrocoele or lymphoedema for which other causes of these findings have been excluded. Confirmed case: A person with positive laboratory diagnosis of microfilaremia in blood smear, filarial antigenaemia or positive ultrasound test. MalariaUncomplicated malaria Any person living in area at risk of malaria with fever or history of fever within 24 hours; without signs of severe disease (vital organ dysfunction) is diagnosed clinically as malaria. Confirmed uncomplicated malaria Any person with fever or history of fever within 24 hours; and with laboratory confirmation of diagnosis by malaria blood film or other diagnostic test for malaria parasites. Unconfirmed severe malaria Any patient living in area at risk of malaria hospitalised with severe febrile disease with accompanying vital organ dysfunction diagnosed clinically Confirmed Severe malaria Any patient hospitalized with P. falciparum asexual parasitaemia as confirmed by laboratory tests with accompanying symptoms and signs of severe disease (vital organ dysfunction) diagnosed through laboratory.\n",
      "Score: 0.818711221\n",
      "\n",
      "\n",
      "Document UUID: c2ac4183-a5ae-496a-98f0-48413c625caf\n",
      "Chunk ID: 0.0\n",
      "Chunk ID: 17Priority Diseases and Conditions Disease/Condition Standard case definition for suspectedcases Confirmed cholera case : A suspected case with Vibrio cholerae O1 or O139 confirmed by culture or P CR polymerase chain reaction and, in countries where cholera is not present or has been eliminated, the Vibrio cholerae O1 or O139 strain is demonstrated to betoxigenic Dengue FeverDengue Fever Suspected case: Any person with acute febrile illness of 2-7 days duration with 2 or more of the following: headache, retro-orbital pain, myalgia, arthralgia, rash, haemorrhagic manifestations, leucopenia. Dengue Fever Confirmed case: A suspected case with laboratory confirmation (positive IgM antibody, fourfold or greater increase in IgG antibody titers in paired (acute and convalescent) serum specimens, positive PCR or Isolation of the dengue virus using cell culture). Dengue Haemorrhagic Fever : A probable or confirmed case of dengue with bleeding tendencies as evidenced by one or more of the following: positive tourniquet test; petechieae, ecchymoses or purpura; bleeding: mucosa, gastrointestinal tract, injection sites or other; haematemesis or melaena; and thrombocytopenia (100000 cells or less per mm3) and evidence of plasma leakage due to increased vascular permeability, manifested by one or more of the following: 20% rise in average haematocrit for age and sex, 20% drop in haematocrit following volume replacement therapy compared to baseline, signs of plasma leakage (pleural effusion, ascites, hypo-proteinaemia). Dengue Shock Syndrome : All the above criteria, plus evidence of circulatory failure manifested by rapid and weak pulse, and narrow pulse pressure ( ≤\u000320\u0003mm\u0003Hg)\u0003or\u0003hypotension \u0003for\u0003age,\u0003cold,\u0003clammy\u0003skin\u0003and\u0003altered\u0003mental\u0003status. DiabetesSuspected new case : Any person presenting the following symptoms: (a)Increased thirst (b)Increased hunger (c)Frequent urination Confirmed new case: Any person with a fasting 6.1 mmol/L (110 mg/dl) Or venous plasma glucose measurement of ≥\u00037\u0003mmol/L\u0003(126\u0003mg/dl)\u0003or\u0003capillary\u0003glucose ≥\u0003 6.1 mmol/L (110 mg/dl) OR Any person with a non-fasting glucose ≥\u000311.1\u0003mmol/L\u0003(200mg/dl) \u0003Or\u0003venous\u0003plasma\u0003glucose\u0003measurement of ≥\u000311.1mmol/L \u0003(200\u0003mg/dl) Diarrhoea with blood (Dysentery)Suspected case : A person with (abdominal pain) and diarrhoea with visible blood in stool. Confirmed case : Suspected case with stool culture positive for Shigella dysenteriae type 1. Diarrhoea with dehydration in children less than five years of ageSuspected case : Passage of three or more loose or watery stools in the past 24 hours with or without dehydration and: Some dehydration --two or more of the following signs: restlessness, irritability; sunken eyes; thirsty; skin pinch goes back slowly, or Severe dehydration --two or more of the following signs: lethargy or unconsciousness; sunken eyes; not able to drink or drinking poorly; skin pinch goes back very slowly. Confirmed case : Suspected case confirmed with stool culture for a known enteric pathogen.\n",
      "Score: 0.817537904\n",
      "\n",
      "\n",
      "Document UUID: c2ac4183-a5ae-496a-98f0-48413c625caf\n",
      "Chunk ID: 0.0\n",
      "Chunk ID: 48Annex1G: List of national laboratories for confirming priority diseases and conditions Periodically update the list of laboratories in your district or those specified by the national level for confirming priority diseases and conditions. Include in the list whom to contact for assistance. The following list is an example. Example: Priority disease, conditions and events Focal Person, Name of Lab, address, phone number, email PolioExample: John Zimbe; National Laboratory, 145 Kenyatta Road, Pretoria, SA; 234-701342555 Cholera HIV Tuberculosis Measles Plague Human influenza caused by a new subtype Rift Valley disease Dengue fever Public health events of national or international concern Anthrax Chikungunya Typhoid fever\n",
      "Score: 0.813245475\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the top results\n",
    "for result in top_k_results:\n",
    "    print(f\"Document UUID: {result['metadata']['doc_uuid']}\")\n",
    "    print(f\"Chunk ID: {result['metadata']['chunk_id']}\")\n",
    "    print(f\"Chunk ID: {result['metadata']['content']}\")\n",
    "    print(f\"Score: {result['score']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pinecone\n",
    "from pinecone import Pinecone\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "# Pinecone setup (initialize and connect to the index)\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "index_name = \"idsr\"  # The same index name used during the embedding\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Embedding model\n",
    "embedding_model = OpenAIEmbedding(model_name=\"text-embedding-ada-002\")\n",
    "\n",
    "# Query function\n",
    "def query_pinecone(query_text, top_k=5, namespace=\"pandas\", threshold=0.7, document_filter=None):\n",
    "    # Convert the query text to an embedding\n",
    "    query_embedding = embedding_model.get_text_embedding(query_text)\n",
    "\n",
    "    # Set up the filter (optional)\n",
    "    pinecone_filter = None\n",
    "    if document_filter:\n",
    "        pinecone_filter = {\"doc_uuid\": {\"$eq\": document_filter}}\n",
    "\n",
    "    # Query Pinecone with the embedding\n",
    "    query_result = index.query(\n",
    "        namespace=namespace,  # Use the same namespace as used in the embedding script\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        include_values=True,\n",
    "        filter=pinecone_filter\n",
    "    )\n",
    "\n",
    "    # Filter results by the score threshold (optional)\n",
    "    relevant_results = [item for item in query_result['matches'] if item['score'] >= threshold]\n",
    "\n",
    "    return relevant_results\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "query_text = \"Compare the laboratory confirmation methods for Chikungunya and diabetes, and which diseases are diagnosed through blood glucose measurements?\"  # Your query here\n",
    "document_filter = \"c2ac4183-a5ae-496a-98f0-48413c625caf\"\n",
    "top_k_results = query_pinecone(query_text, top_k=5, document_filter=document_filter)\n",
    "\n",
    "# Display the top results\n",
    "for result in top_k_results:\n",
    "    print(f\"Document UUID: {result['metadata']['doc_uuid']}\")\n",
    "    print(f\"Chunk ID: {result['metadata']['chunk_id']}\")\n",
    "    print(f\"Score: {result['score']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# router = APIRouter()\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "# Define paths\n",
    "RAW_DATA = \"./data/raw\"\n",
    "PERSIST_DIR = \"./data/storage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or create index\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    documents = SimpleDirectoryReader(RAW_DATA).load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents=documents, show_progress=True)\n",
    "    index.storage_context.persist(PERSIST_DIR)\n",
    "else:\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_engine.query(\"how to detect and report priority diseases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Query Engine\n",
    "def create_query_engine(persist_dir=\"./data/storage\"):\n",
    "    # If the index is already stored locally, load it\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "    index = load_index_from_storage(storage_context=storage_context)\n",
    "    \n",
    "    # Create a query engine\n",
    "    query_engine = VectorQueryEngine(index)\n",
    "    \n",
    "    return query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Function\n",
    "def query_llama_engine(query_text, top_k=5, document_filter=None):\n",
    "    query_engine = create_query_engine()  # Initialize query engine\n",
    "    \n",
    "    # Perform the query using the engine\n",
    "    response = query_engine.query(query_text)\n",
    "    \n",
    "    # Show top results\n",
    "    pprint_response(response)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VectorQueryEngine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m query_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow to detect and report priority diseases\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# The query\u001b[39;00m\n\u001b[0;32m      2\u001b[0m document_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc2ac4183-a5ae-496a-98f0-48413c625caf\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Optional document filtering\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m top_k_results \u001b[38;5;241m=\u001b[39m query_llama_engine(query_text, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, document_filter\u001b[38;5;241m=\u001b[39mdocument_filter)\n",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m, in \u001b[0;36mquery_llama_engine\u001b[1;34m(query_text, top_k, document_filter)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_llama_engine\u001b[39m(query_text, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, document_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m----> 3\u001b[0m     query_engine \u001b[38;5;241m=\u001b[39m create_query_engine()  \u001b[38;5;66;03m# Initialize query engine\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Perform the query using the engine\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     response \u001b[38;5;241m=\u001b[39m query_engine\u001b[38;5;241m.\u001b[39mquery(query_text)\n",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m, in \u001b[0;36mcreate_query_engine\u001b[1;34m(persist_dir)\u001b[0m\n\u001b[0;32m      5\u001b[0m index \u001b[38;5;241m=\u001b[39m load_index_from_storage(storage_context\u001b[38;5;241m=\u001b[39mstorage_context)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create a query engine\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m VectorQueryEngine(index)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_engine\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VectorQueryEngine' is not defined"
     ]
    }
   ],
   "source": [
    "query_text = \"how to detect and report priority diseases\"  # The query\n",
    "document_filter = \"c2ac4183-a5ae-496a-98f0-48413c625caf\"  # Optional document filtering\n",
    "top_k_results = query_llama_engine(query_text, top_k=5, document_filter=document_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model (optional if llama_index takes care of embeddings internally)\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "embedding_model = OpenAIEmbedding(model_name=\"text-embedding-ada-002\")\n",
    "\n",
    "# Initialize Query Engine\n",
    "def create_query_engine(persist_dir=\"./data/storage\"):\n",
    "    # If the index is already stored locally, load it\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "    index = load_index_from_storage(storage_context=storage_context)\n",
    "    \n",
    "    # Create a query engine\n",
    "    query_engine = VectorQueryEngine(index)\n",
    "    \n",
    "    return query_engine\n",
    "\n",
    "# Query Function\n",
    "def query_llama_engine(query_text, top_k=5, document_filter=None):\n",
    "    query_engine = create_query_engine()  # Initialize query engine\n",
    "    \n",
    "    # Perform the query using the engine\n",
    "    response = query_engine.query(query_text)\n",
    "    \n",
    "    # Show top results\n",
    "    pprint_response(response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    query_text = \"how to detect and report priority diseases\"  # The query\n",
    "    document_filter = \"section_1\"  # Optional document filtering\n",
    "    top_k_results = query_llama_engine(query_text, top_k=5, document_filter=document_filter)\n",
    "\n",
    "    # Optionally process or display results further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.vector_stores'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvector_stores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpinecone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PineconeVectorStore\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.vector_stores'"
     ]
    }
   ],
   "source": [
    "from llama_index.vector_stores.pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.core.pinecone'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorStoreIndex, StorageContext\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpinecone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PineconeVectorStore\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.core.pinecone'"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.core.pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.vector_stores'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDirectoryReader, StorageContext, load_index_from_storage, VectorStoreIndex, ServiceContext\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorStoreIndex, SimpleDirectoryReader\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvector_stores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpinecone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PineconeVectorStore\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbedding\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpinecone\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.vector_stores'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext, load_index_from_storage, VectorStoreIndex, ServiceContext\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import pinecone\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "# Pinecone setup (initialize and connect to the index)\n",
    "pinecone.init(api_key=os.environ.get(\"PINECONE_API_KEY\"), environment=os.getenv(\"PINECONE_ENV\"))\n",
    "pinecone_index_name = \"idsr\"  # The same index name used during the embedding\n",
    "\n",
    "# Check if the index exists\n",
    "if pinecone_index_name not in pinecone.list_indexes():\n",
    "    raise ValueError(f\"Index '{pinecone_index_name}' does not exist. Please create the index first.\")\n",
    "\n",
    "# Set up Pinecone vector store\n",
    "pinecone_index = pinecone.Index(pinecone_index_name)\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "\n",
    "# Embedding model (OpenAI)\n",
    "embedding_model = OpenAIEmbedding(model_name=\"text-embedding-ada-002\")\n",
    "service_context = ServiceContext.from_defaults(embedding_model=embedding_model)\n",
    "\n",
    "# Load the query engine\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "query_engine = VectorStoreIndex(storage_context=storage_context, service_context=service_context).as_query_engine()\n",
    "\n",
    "# Function to query using LlamaIndex's Query Engine\n",
    "def query_llama_index(query_text, top_k=5):\n",
    "    response = query_engine.query(query_text, top_k=top_k)\n",
    "    return response\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    query_text = \"how to detect and report priority diseases\"  # Example query\n",
    "    response = query_llama_index(query_text, top_k=5)\n",
    "\n",
    "    # Print the response (LlamaIndex will format it neatly)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastapi import APIRouter, Depends, HTTPException, status\n",
    "# from fastapi.responses import HTMLResponse\n",
    "# from sqlalchemy.orm import Session\n",
    "# from app.api.v1.endpoints.auth import get_current_user\n",
    "# from app.database import get_db\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "# from app.api.v1.models import User, Chat\n",
    "# from app.api.v1.schemas import MakeQuery, ChatCreate, ChatHistoryCreate, ChatHistoryResponse\n",
    "# from app.api.v1.crud import create_chat, create_chat_history, get_chat_histories\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# router = APIRouter()\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "# Define paths\n",
    "RAW_DATA = \"./data/raw/440c49bd-c539-4f4d-b6ca-ef299d7a3b03\"\n",
    "PERSIST_DIR = \"./data/storage/440c49bd-c539-4f4d-b6ca-ef299d7a3b03\"\n",
    "\n",
    "# Load or create index\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    documents = SimpleDirectoryReader(RAW_DATA).load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents=documents, show_progress=True)\n",
    "    index.storage_context.persist(PERSIST_DIR)\n",
    "else:\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"How is review the flow of information at the reporting site done?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reviewing the flow of information at the reporting site is done by ensuring that all reporting sites, including secondary and tertiary hospitals in the catchment area, are visited during supervisory visits. Clinicians are required to record information legibly in patient registers using recommended case definitions so that health workers can reliably record the required diagnoses on the tally sheet at the end of the day.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.pprint_utils import pprint_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: Chikungunya is confirmed through laboratory tests like\n",
      "PCR (Polymerase Chain Reaction) or serology, while diabetes is\n",
      "diagnosed through blood glucose measurements. Diseases diagnosed\n",
      "through blood glucose measurements include diabetes.\n",
      "______________________________________________________________________\n",
      "Source Node 1/2\n",
      "Node ID: 97780ad2-479e-4dbc-b361-e7673a3b1376\n",
      "Similarity: 0.7958168845061465\n",
      "Text: 56Table 2.1: Diseases, conditions or events requiring immediate\n",
      "reporting 1. Acute haemorrhagic fever syndrome (Ebola Virus  Disease,\n",
      "Marburg, Lassa Fever, RVF, Crimean- Congo)  2. Adverse effects\n",
      "following immunization (AEFI) 3. Anthrax 4. Bacterial meningitis  5.\n",
      "Chikungunya 6. Cholera 7. Dengue fever 8. Diarrhoea with blood (\n",
      "Shigellosis ) 9....\n",
      "______________________________________________________________________\n",
      "Source Node 2/2\n",
      "Node ID: 6e33ba43-3497-439a-8321-cb5f33c040a6\n",
      "Similarity: 0.7912018376845786\n",
      "Text: 77Annex2G: IDSR case-based laboratory reporting form IDSR case-\n",
      "based Laboratory Reporting Form Part I: Referring health worker to\n",
      "complete this form and a copy sent to the laboratory  with the\n",
      "specimen Variables Answers 1Date of specimen collection\n",
      "(day/month/year) 2Suspected Disease or Condition 3Specimen type *\n",
      "4Specimen unique identifier ** 5...\n"
     ]
    }
   ],
   "source": [
    "pprint_response(response, show_source=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastapi import APIRouter, Depends, HTTPException, status\n",
    "# from fastapi.responses import HTMLResponse\n",
    "# from sqlalchemy.orm import Session\n",
    "# from app.api.v1.endpoints.auth import get_current_user\n",
    "# from app.database import get_db\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Pinecone.\n",
    "# from app.api.v1.models import User, Chat\n",
    "# from app.api.v1.schemas import MakeQuery, ChatCreate, ChatHistoryCreate, ChatHistoryResponse\n",
    "# from app.api.v1.crud import create_chat, create_chat_history, get_chat_histories\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# router = APIRouter()\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "# Define paths\n",
    "RAW_DATA = \"./data/raw\"\n",
    "PERSIST_DIR = \"./data/storage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = [\n",
    "    \"440c49bd-c539-4f4d-b6ca-ef299d7a3b03\",\n",
    "    \"5873ebb0-78e4-4fd7-b981-5c095db9c79a\",\n",
    "    \"5ee88974-4049-45ba-a2a6-62f40911d8e6\",\n",
    "    \"7dad4114-2f20-4f77-939d-f2009ae62818\",\n",
    "    \"84117349-e425-4f22-9f7c-b69f843c848e\",\n",
    "    \"90bcde30-9de4-4b74-812f-354f5365c70f\",\n",
    "    \"c2ac4183-a5ae-496a-98f0-48413c625caf\",\n",
    "    \"c4ef9e32-1b62-467d-8a7f-78df9670da17\",\n",
    "    \"e2f9539c-97c7-435b-ac3f-5cee46c39218\",\n",
    "    \"fc812ad2-edd4-4684-86a3-db98b2bb3ec1\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_file_names(directory_path):\n",
    "    # Get a list of all files in the directory\n",
    "    file_names = os.listdir(directory_path)\n",
    "    \n",
    "    # Optionally, filter out directories and keep only files\n",
    "    file_names = [file for file in file_names if os.path.isfile(os.path.join(directory_path, file))]\n",
    "    \n",
    "    return file_names\n",
    "\n",
    "# Example usage\n",
    "# directory_path = \"./your_directory\"\n",
    "paths = []\n",
    "for path in path_list:\n",
    "    # files = read_file_names(RAW_DATA+f\"/{path}\")\n",
    "    paths.append(RAW_DATA+f\"/{path}\")\n",
    "# for file in files:\n",
    "#     print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/raw/440c49bd-c539-4f4d-b6ca-ef299d7a3b03',\n",
       " './data/raw/5873ebb0-78e4-4fd7-b981-5c095db9c79a',\n",
       " './data/raw/5ee88974-4049-45ba-a2a6-62f40911d8e6',\n",
       " './data/raw/7dad4114-2f20-4f77-939d-f2009ae62818',\n",
       " './data/raw/84117349-e425-4f22-9f7c-b69f843c848e',\n",
       " './data/raw/90bcde30-9de4-4b74-812f-354f5365c70f',\n",
       " './data/raw/c2ac4183-a5ae-496a-98f0-48413c625caf',\n",
       " './data/raw/c4ef9e32-1b62-467d-8a7f-78df9670da17',\n",
       " './data/raw/e2f9539c-97c7-435b-ac3f-5cee46c39218',\n",
       " './data/raw/fc812ad2-edd4-4684-86a3-db98b2bb3ec1']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(paths[0]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/storage/440c49bd-c539-4f4d-b6ca-ef299d7a3b03'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERSIST_DIR+f\"/{paths[0].split('/')[-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771dc6794a10450d9df4c05e4fc21597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe59fdd893c4152961b73b29621aaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797baa38a8d24925bc8d5831daf16051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581b31f20098459eb97aaf27011442ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e30f3a017b4ce5b1b2370f46429442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e49cc30fece42b381af412a53d8f193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4946b569ca964aadbd360d4634c54d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ef6a82d5a443ceb7093b2fc06505ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac937dd3526d4437a4b9c0dc24fb52ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7c25177c304836bcd02c28659636d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d768af2e61724526bdcc67072b1f4b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338580dca3144e78b8c5f83f52d737c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319583eaf0994536af5f75a42bf1b391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b434b6a8d0454050819b32dcff767813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df440a2fbc94c9cb5bf7ea2a8b0d0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d021d1fce5c49e5a9770aad0cd71576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89356c9db844084895f05ea254cdbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4639c2bb0bcc4ba88c29f46c6970265e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f3c3041e7549488dbb52a1afb2d80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af68cd4a9d924af5ac28bb2992889711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for path in paths:\n",
    "    # files = read_file_names(RAW_DATA+f\"/{path}\")\n",
    "    # print()\n",
    "    # Load or create index\n",
    "\n",
    "    # try:\n",
    "    if not os.path.exists(path):\n",
    "        documents = SimpleDirectoryReader(path).load_data()\n",
    "        index = VectorStoreIndex.from_documents(documents=documents, show_progress=True)\n",
    "        index.storage_context.persist(PERSIST_DIR+f\"/{path}\")\n",
    "        # else:\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR+f\"/{paths[0].split('/')[-1]}\")\n",
    "        index = load_index_from_storage(storage_context=storage_context)\n",
    "    # except Exception as e:\n",
    "    #     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "query_text = \"how to detect and report priority diseases\"\n",
    "print(query_engine.query(query_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
